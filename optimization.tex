\documentclass[reqno]{amsart}
\usepackage[toc,page]{appendix}

\setlength{\parindent}{0pt}
\setlength{\parskip}{\baselineskip}

\DeclareMathOperator*{\argmin}{arg\,min\,}
\DeclareMathOperator*{\argmax}{arg\,max\,}

\numberwithin{equation}{section}

\title{Gauss-Newton Optimization}
\author{Adam Williams}

\begin{document}

\maketitle

\tableofcontents

\section{Introduction}

\section{General Unconstrained Optimization in Euclidean Spaces}

\subsection{The General Unconstrained Problem}

The \textbf{general unconstrained optimization problem} for $\mathbb R^n$ consists of
an \textbf{objective function} $f : \mathbb R^n \to \mathbb R$, where we wish to find
$$
    x^* = \argmin_{x \in \mathbb R^n} f(x).
$$
If $f$ is affine ($f = Ax + b$), then there is a closed form solution (see the appendix
section on linear least-squares methods). Otherwise, we solve the problem numerically
by attempting to approximate a \textbf{stationary point} of $f$, that is, a point
$x \in \mathbb R^n$ for which $df_x = 0$. Via Taylor's theorem, any
\textbf{local minimizer} of $f$ is necessarily a stationary point.

The converse, however --- that a stationary point is a local minimizer of $f$ ---
is not in generally true. It is, however, true in the case where the second
derivative (Hessian matrix) of $f$ at $x$ is positive-definite, i.e. $H(f)_x > 0$. If
$H(f) > 0$ globally, then $f$ is called \textbf{convex}, and all stationary
points are local minimizers. Hence convex functions are of particular interest
in numerical optimization.

The goal of unconstrained numerical optimization is generally to, given an initial
point $x_0 \in \mathbb R^n$, construction a sequence $(x_k)_{k \in \mathbb N}$
that converges to a stationary point $x^*$ of $f$, with some satisfactory rate of
convergence:
\begin{align*}
    x_k &\to x^*, \\
    df_{x^*} &= 0.
\end{align*}
In general, it is difficult to distinguish between local minimizers and global minimizers,
and so a crucial task in implementing optimizations to make sure one starts in the
``correct basin.'' How to solve this initialization problem is a domain-specific
engineering problem, and so no such topic will be covered by these notes. These notes
cover the problem of reaching a local minimizer given an initial guess.

The problem of constructing the next point $x_{k+1}$ given $x_k$ is usually formulated
as the problem of finding the optimal ``step'' $v_k$, and setting
$$
    x_{k+1} = x_k + v_k.
$$

\subsection{Gradient Descent}

Given a point $x \in \mathbb R^n$, the gradient $\nabla f(x)$ is the ``steepest
ascent'' direction for $f$ at $x$,
in the sense that $u = \nabla f(x) / \| \nabla f(x) \|$ maximizes
the directional derivative $df_x u = \nabla f(x)^T u$ over all unit vectors $u$.
\textbf{Gradient descent} is the optimization method of choosing each step $v_k$ to
be in the direction of the (negative) gradient.

Gradient descent can be thought of as using a first-order approximation to $f$:
\begin{align*}
    f(x_k + v) &= m^1_k(v) + o(\|v\|^2),
\end{align*}
where
\begin{align*}
    m^1_k(v) &= f(x_k) + \nabla f(x_k)^T v \\
        &= f(x_k) + df_{x_k} v. \\
\end{align*}
When $\nabla f_k \ne 0$, $m^1_k$ of course has no local extrema, and thus we cannot minimize
it globally. The best we can do is minimize it subject to the constraint $\|v\| = \alpha$,
which gives the gradient descent direction
$$
    v^{GD}_k = - \alpha \nabla f_k / \| \nabla f_k \|.
$$

While gradient descent has the advantage that it only requires the computation of
first derivatives, its
convergence can be quite slow, since its steps do not take curvature
into account and thus can ``bounce'' back and forth a lot around basins with non-constant
curvature.

There is of course also the problem of choosing the step size $\alpha$, since
gradient descent gives only directional information. Methods like this
which involve choosing
an optimal step direction, following by a magnitude, are called \textbf{line search}
methods, and a thorough discussion of these methods is beyond the scope of these notes.

\subsection{Newton's Method}

\textbf{Newton's method} improves upon gradient descent by taking curvature
information into account; we approximate $f$ to second order via
$$
    f(x_k + v) = m^2_k(v) + o(\|v\|^3),
$$
where
\begin{align*}
    m^{N}_k(v) &= f_k + \nabla f_k^T v + \frac{1}{2} v^T \nabla^2 f_k v, \\
\end{align*}
where $\nabla^2 f_k$ denotes the Hessian matrix (i.e. the matrix of the second
derivative of $f$).

Crucially, if $\nabla^2 f > 0$, i.e. if the Hessian is positive-definite, then
the model function $m^2_k$ is convex, and has a unique local minimum, which is
the \textbf{Newton step} for the optimization state, and can be solved for by
setting $d m^2_k(v) = 0$, yielding
$$
    v^N_k = - [\nabla^2 f_k]^{-1} \nabla f_k.
$$
It is worth noting that this is the solution to the linear equation
$$
    \nabla^2 f_k v + \nabla f_k = 0,
$$
and so we are actually solving a linear least-squares problem
$$
    v^N_k = \argmin_{v \in \mathbb R^n} \left\| \nabla^2 f_k v + \nabla f_k \right\|_2^2.
$$

In practice, computing the full Hessian at each step can be prohibitively expensive,
and one uses an approximation of the Hessian satisfying some desirable conditions.
Such methods are known as \textbf{quasi-Newton methods}.

\subsection{Trust Region Methods}

Taylor's theorem only guarantees that the quadratic approximation $m^2_k$ of $f$
is close to $f$ when its argument $v$ is sufficiently small. Hence it may be
ill-advised to take the ``global'' Newton step if said step is too large. Hence
we may want to decide that there is some neighborhood
of $x_k$ within which we ``trust'' that the
quadratic approximation is ``good enough''.

A \textbf{trust region method} applies Tikhonov regularization to the step-level
least-squares minimization problem: Instead of minimizing globally, we solve
the norm-constrained problem:
$$
    v^{N,\Gamma}_k = \argmin_{v \in \mathbb R^b} \left\| \nabla^2 f_k v + \nabla f_k \right\|_2^2
        + \left\| \Gamma v \right\|_2^2,
$$
for some \textbf{damping} matrix $\Gamma$. Note that, if $\Gamma = 0$ and 
$\nabla^2 f_k$ is positive-definite, then this reduces to the usual Newton step.

If $\Gamma > 0$, then the trust region constrained step has an exact solution, obtained
by solving the regularized least-squares problem:
$$
    v^{N,\Gamma}_k = \left([\nabla^2 f_k]^T [\nabla^2 f_k] + \Gamma^T \Gamma\right)^{-1}
        [\nabla^2 f_k]^T \nabla f_k.
$$

A common approach is to take $\Gamma = \lambda I$, so that $\Gamma v = \lambda v$,
and increase/decrease the size of the trust region (determined by the magnitude
of $\Gamma^{-1}$) depending on how well the model function predicts the change in
$f$ with each step.

\subsection{Convergence Theory}

\section{Gauss-Newton in Euclidean Spaces}
\subsection{The Gauss-Newton Method}
\subsection{Maximum Likelihood Formulation}
\subsection{Levenberg-Marquardt Damping}
\subsection{Robust Loss Functions}
\subsection{Convergence Theory}

\section{Extension to Manifolds}

\section{Implementation Concerns}
\subsection{Sparsity of Large-Scale Problems}
\subsection{Variable Elimination Orderings}
% ^ see wikipedia pages for Variable Elimination and Factor graph
\subsection{Gauge Freedom}
\subsection{Poorly Conditioned Problems}
\subsection{Observability}

\appendix

\section{Calculus on Euclidean Spaces}

\subsection{Differentiable Functions}

A function $f : U \subseteq \mathbb R^m \to \mathbb R^n$ is \textbf{differentiable} at $x \in U$
if there exists a linear map $A : \mathbb R^m \to \mathbb R^n$ such that
$$
    \lim_{\|v\| \to 0} \frac{\|f(x + v) - f(x) - A v\|}{\|v\|} = 0.
$$
That is, $f$ may be approximated to first order near $x$ by $A$:
$$
    f(x+v) = f(x) + A v + o(\|v\|),
$$
using Landau notation. If the linear map $A$ exists, it is called the \textbf{differential}
of $f$ at $x$, and is denoted $df_x$. The value $df_x v$ can be thought of as the
\textbf{directional derivative} of $f$ at $x$ along $v$, and in fact
$$
    df_x v = \left.\frac{d}{dt}\right|_{t=0}f(x + tv).
$$

With respect to the standard bases, the matrix differential is given
by the matrix of partial derivatives, which is called the \textbf{Jacobian matrix}:
$$
    [df_x] = J(f)_x =
        \frac{\partial f }{\partial x^T} =
        \begin{bmatrix} \frac{\partial f_1}{\partial x_1} & \cdots & \frac{\partial f_1}{\partial x_n} \\
        \vdots & \ddots & \vdots \\ 
        \frac{\partial f_m}{\partial x_1} & \cdots & \frac{\partial f_m}{\partial x_n}
        \end{bmatrix}
$$

Formally, $df_x$ should be seen not as a linear map on $\mathbb R^n$, but
as a linear map on the ``copy'' of $\mathbb R^n$ whose origin is at $x$, otherwise known as
the \emph{tangent space} $T_x \mathbb R^n$. Since $T_x \mathbb R^n \cong \mathbb R^n$, we
drop this formalism for Euclidean spaces. See the section below on differentable manifolds.

\subsection{Twice-differentiable Functions}

If $f$ is differentable on all of its domain $U$, then we can consider the map
$df : U \to L(\mathbb R^n, \mathbb R^m)$ given by $x \mapsto df_x$. We can also consider the
differentiability of this map: naturally, $d^2f_x$ should be a linear transformation from
$\mathbb R^n$ to $L(\mathbb R^n, \mathbb R^m)$. Making the natural association between
$L(\mathbb R^n, L(\mathbb R^n, \mathbb R^m))$ and the space of bilinear maps
$L^2(\mathbb R^n \times \mathbb R^n, \mathbb R^m)$, we say that $f$ is twice-differentiable
at $x$ if there exists a bilinear map $B: \mathbb R^n \times \mathbb R^n \to \mathbb R^m$ such that
$$
    \lim_{w \to 0} \frac{\|df_{x+w} v - df_x v - B(v, w) \|}{\|w\|} = 0
$$
uniformly over bounded subsets of $\mathbb R^n$. If such a $B$ exists, it is called the
second derivative of $f$ at $x$ and is denoted $d^2 f_x$. It can be thought of as a
second directional derivative:
\begin{align*}
    d^2f_x(v, w) &= \left. \frac{d}{ds} \right|_{s=0} df_{x + sw}v \\
        &= \left. \frac{d^2}{dsdt} \right|_{s,t=0} f(x + sw + tv).
\end{align*}

Note that $d^2f_x \in L^2(\mathbb R^n \times \mathbb R^n, \mathbb R^m)$ can be viewed as
a type-$(2, 1)$ tensor, i.e. $d^2f_x \in \mathbb R^n \otimes \mathbb R^n \otimes (\mathbb R^m)^*$.
With respect to the standard bases, it can be specified by each of the
$m$ values that it takes on each of the $n^2$ basis vector pairs $(e_i, e_j)$. Using tensor
notation:
$$
    [d^2f_x]_{ij}^k = d^2f_x(e_i,e_j)_k = \frac{\partial^2 f_k}{\partial x_i \partial x_j},
$$
so that the $k$-th component $f_k$ is given by the \textbf{Hessian matrix}:
$$
    d^2f_x(v,w)_k = v^T  H(f_k)_x w,
$$
where
$$
    H(g)_x = \frac{\partial^2 g}{\partial x x^T} =
        \begin{bmatrix} \frac{\partial^2 g}{\partial x_1^2} & \cdots & \frac{\partial^2 g}{\partial x_1 \partial x_n} \\
        \vdots & \ddots & \vdots \\ 
        \frac{\partial^2 g}{\partial x_n \partial x_1} & \cdots & \frac{\partial^2 g}{\partial x_n^2} \\
        \end{bmatrix}
$$
In the case where the second partial derivatives are continuous, they commute, and thus
the Hessian is symmetric.

\subsection{Calculus of Real-Valued Functions}


\subsubsection{The Differential and Gradient}

The \textbf{gradient} of $f$ is defined as the dual of the the differential,
and is denoted $\nabla f(x) \in \mathbb R^n$, so that
$$
    \nabla f(x)^Tv = df_x v
$$
for all $v$. The gradient is given in standard basis coordinates as
$$
    \nabla f(x) = (df_x)^{\sharp} = \left(\frac{\partial f}{\partial x^T}\right)^T = \sum_{i=1}^n \frac{\partial f}{\partial x_i} \frac{\partial}{\partial x_i},
$$
Note that, with an eye towards generalizing to manifolds, we use the notation $\frac{\partial}{\partial x_i}$ to
denote the $i$-th standard basis vector on $\mathbb R^n$. Similarly, we denote the corresponding dual basis by
$d x^i$.

The gradient can be interpreted as the vector field pointing in the
\emph{direction of steepest ascent} of $f$, which can be observed by noting that the directional
derivative $\nabla f(x)^T v$ is maximized when $v$ is parallel to $\nabla f(x)$.

\subsubsection{The Second Derivative and the Hessian}

Also note that in the $m=1$ case, the second derivative $d^2f_x$ is simply a bilinear form
on $\mathbb R^n$, and is fully described by the Hessian matrix $H(f)_x =
\frac{\partial^2 f}{\partial x x ^T}$. Using tensor notation, we can write the second derivative
in terms of the basis covectors:
$$
    d^2f_x = H(f)_x = \sum_{i,j} \frac{\partial f}{\partial x_i \partial x_j} dx^i \otimes dx^j,
$$
where $(\phi \otimes \psi)(v,w) = \phi(v) \psi(w)$ for $\phi, \psi \in (\mathbb R^n)^*$.

In this context, the Hessian is often denoted $\nabla^2f(x)$, and this notation can be made
rigorous using the machinery of differential geometry.

\subsubsection{Taylor's Theorem}

For one-variable functions $g : \mathbb R \to \mathbb R$, \textbf{Taylor's Theorem} states
that if $g$ is $k$ times differentable at $a$, then $g$ can be approximated to $k$-th
order by its Taylor polynomial: There exists a function $h_k : \mathbb R \to \mathbb R$ such
$$
    g(a+h) = g(a) + g'(a)h + \frac12 g''(a)h^2 + \cdots + \frac{1}{k!} g^{(k)}(a) h^k +
        o(|h|^k).
$$
We can derive a Taylor theorem for multivariate functions $f$ by applying the univariate Taylor
theorem to the function $t \mapsto f(x + tv)$ and then setting $t=1$. For $k=1$, this gives
$$
    f(x + v) = f(x) + \nabla f(x)^T v + o(\|v\|).
$$
Note this is precisely the definition of the first derivative.

And for $k=2$, we have
$$
    f(x + v) = f(x) + \nabla f(x)^T v + \frac{1}{2} v^T \nabla^2 f(x) v + o(\|v\|^2).
$$

\section{Lagrange Multipliers}

The method of \textbf{Lagrange multipliers} is used to find stationary points of an objective
function $f: \mathbb R^n \to \mathbb R$ subject to a constraint of the form $g(x) = 0$,
by replacing the constrained problem with an unconstrained one.
The main point is to note the \emph{necessary condition}
for $x$ to be a stationary point for $f$, that there exists $\lambda \in \mathbb R$ such that
$\nabla_x f(x) = \lambda \nabla_x g(x)$. Otherwise, there is some non-zero component
of $\nabla_x f(x)$ along the contour $g(x) = 0$, and thus an increment along $g(x) = 0$
decreases $f$.

Motivated by this observation, we introduce the \textbf{Lagrange function} $\mathcal L :
\mathbb R^n \times \mathbb R \to \mathbb R$ defined by
$$
\mathcal L(x,\lambda) = f(x) - \lambda g(x),
$$
where $\lambda$ is called the \textbf{Lagrange multiplier} for the problem. Then, we have
the following equivalence:
$$
    \nabla_{x, \lambda} \mathcal L (x,\lambda) = 0 \iff
    \begin{cases}
        \nabla_x f(x) &= \lambda \nabla_x g(x) \\
        g(x)          &= 0.
    \end{cases}
$$
Hence, the condition that there exists $\lambda$ such that $(x,\lambda)$ is a stationary point
for $\mathcal L$ is a necessary condition for $x$ to be stationary point of $f$ subject to
$g(x) = 0$. So we can proceed to solve the unconstrained problem, and then check whether each of
our solutions provides a solution to the original problem.

\section{Linear Least-Squares Methods}
\subsection{The Linear Problem}

\emph{Generalized linear least-squares} is a technique for solving the problem
\begin{equation}
    x^* = \argmin_{x \in \mathbb R^n} \frac12 \| Ax - y\|_\Sigma^2,
\label{glls}
\end{equation}
where $A \in \mathbb R^{m \times n}$, $y \in \mathbb R^m$, $\Sigma \in \mathbb R^{m \times m}$
is a symmetric, positive-definite matrix, and $\| z \|_\Sigma = (z^T \Sigma^{-1} z)^{1/2}$ is the
Mahalanobis norm on $\mathbb R^m$ induced by $\Sigma$. Differentiating (\ref{glls}) with respect
to $x$ and setting to zero yields the \textbf{normal equations}
\begin{equation}
    A^T \Sigma^{-1} A x = A^T \Sigma^{-1} y.
\label{normal}
\end{equation}
The matrix $A^T \Sigma^{-1} A$ is non-singular if and only if $A$ has full column rank. In this
case, the problem is said to be \emph{well-posed}, or \emph{observable}.
Clearly, if the problem is observable, then there is an analytic solution
$x^* = (A^T \Sigma^{-1} A)^{-1} A^T \Sigma^{-1} y$. Also note that in this case, the Hessian
matrix $A^T \Sigma^{-1} A$ is $>0$ and hence the problem is convex; meaning that the stationary
point $x^*$ is in fact the global minimum. We discuss this case first.

\subsection{Matrix Factorization Solutions}
Assuming that $A^T \Sigma^{-1} A$ is non-singular, solving (\ref{normal}) amounts to inverting a
symmetric positive-definite matrix. There are various methods for accomplishing this:
\subsubsection{Cholesky Decomposition}
A real matrix $M$ is symmetric and positive-definite if and only if it admits
a \textbf{Cholesky decomposition}
$$
M = LL^T,
$$
where $L$ is a non-singular, lower-triangular matrix. Using Cholesky decomposition to solve
$Mx = b$ goes as follows:
\begin{enumerate}
    \item Factor $M = LL^T$.
    \item Solve $Ly = b$ for $y$ by forward substitution.
    \item Solve $L^Tx = y$ for $x$ by back substitution.
\end{enumerate}

Implementation comments:
\begin{itemize}
\item Using the Cholesky decomposition allows the user to only store the $n\times n$ matrix
    $A^T R^{-1} A$, rather than the full $A$, which can be advantageous for highly overconstrained
    problems ($m \gg n$).
\item The Cholesky decomposition has a stability issue, namely that
    $$
    \kappa(A^T \Sigma^{-1} A) \sim \kappa(A)^2,
    $$
    where $\kappa(A)$ is the condition
    number of the matrix, measuring the maximum possible error in $Ax$ relative to $x$. Hence
    a poorly conditioned $A$ can lead easily to a very poorly conditioned $A^T \Sigma^{-1} A$, which
    can be a problem when solving numerical problems.
\end{itemize}

In addition, the Cholesky decomposition can be used to simplify (\ref{glls}), without any
loss of generality: observe that, if we factor $\Sigma^{-1} = L^TL$, and make the
substitutions
\begin{align*}
    A &\leftarrow LA \\
    y &\leftarrow Ly,
\end{align*}
then we have a \emph{normalized} version of the least-squares problem, which is equivalent
to the original:
\begin{equation}
    x^* = \argmin_{x \in \mathbb R^n} \frac12 \| Ax - y\|_2,
\label{gllsn}
\end{equation}
along with normalized normal equations
\begin{equation}
    A^TAx = A^Ty.
\label{normaln}
\end{equation}
For simplicity of calculations, we will address the simplified normal equations
(\ref{normaln}) going forward, keeping in mind that no generality has been lost.

\subsubsection{QR Decomposition}
Any real matrix in $\mathbb R^{m \times n}$ for which $m \ge n$ admits
a \textbf{QR decomposition}
    $$
        A\Pi = QR = Q \begin{bmatrix} R_1 \\ 0 \end{bmatrix}
            = \begin{bmatrix} Q_1 & Q_2 \end{bmatrix}
                \begin{bmatrix} R_1 \\ 0 \end{bmatrix}
                    = Q_1 R_1,
    $$
where $\Pi \in O(n)$ is a permutation matrix,
$R_1 \in \mathbb R^{n \times n}$ is upper-triangular, and
$Q_1 \in \mathbb R^{m \times n}$ and $Q_2 \in \mathbb R^{m \times(m-n)}$
have orthogonal columns (i.e. $Q$ is orthogonal).

To use QR decomposition to solve (\ref{gllsn}), we compute the QR factorization of $A$,
and compute
$$
    \|Ax - y\|_2^2 = \| R(\Pi^Tx) - Q_1^Ty\|_2^2 + \|Q_2^Ty\|_2^2,
$$
which gives the solution
$$
    x^* = \Pi R^{-1} Q_1^Ty.
$$

Implementation comments:
\begin{itemize}
    \item The QR approach is less space-efficient than the Cholesky appraoch, as it requires
        the entire matrix $A$, rather than just $A^TA$.
    \item The error in $x^*$ relative to $y$ where is proportional to $\kappa(A)$,
    rather
    than $\kappa(A)^2$. Hence this method does not degrade the conditioning of the problem like
    the pure Cholesky approach.
\end{itemize}

\subsubsection{Singular Value Decomposition}
Finally, any matrix $A$ admits a \textbf{singular value decomposition}
$$
    A = U \begin{bmatrix} S \\ 0 \end{bmatrix} V^T =
        \begin{bmatrix} U_1 & U_2 \end{bmatrix} \begin{bmatrix} S \\ 0 \end{bmatrix} V^T
        = U_1 S V^T,
$$
where $U \in \mathbb R^{m \times m}$, $V \in \mathbb R^{n \times n}$ are orthogonal,
and $S = \operatorname{diag}(\sigma_1, \ldots, \sigma_n)$, with
$\sigma_1 \ge \ldots \ge \sigma_n$. From the SVD one can compute
$$
    \|Ax - y\|_2^2 = \| S(V^Tx) - U_1^Ty\|_2^2 + \|U_2^Ty\|_2^2,
$$
giving the solution
\begin{align*}
    x^* &= VS^{-1} U_1^Ty \\
        &= \sum_{i=1}^n \frac{u_i^Ty}{\sigma_i} v_i.
\end{align*}
Thus the SVD solution, while expensive to compute, provides very useful information about
the structure of the solution, particularly its
sensitivity with respect to perturbations in $y$ along the basis vectors
$u_i$.

\subsection{Conjugate Gradient Solution}
\subsection{Tikhonov Regularization of Degenerate Problems}
In the case where (\ref{gllsn}) is not well-posed ($A$ has column rank $<n$), it is possible
to find a solution by introducing a \emph{regularization condition} that constrains the
problem sufficiently. Types of regularization can be quite general; we address only the linear
type called \textbf{Tikhonov regularization}.
We introduce a matrix parameter $\Gamma > 0$ and solve the regularized system
\begin{equation}
    x_{\Gamma}^* = \argmin_{x \in \mathbb R^n} \|Ax - y\|_2^2 + \|\Gamma x\|_2^2.
\label{glls-reg}
\end{equation}
This system has the normal equations
\begin{equation}
    (A^TA + \Gamma^T\Gamma) x = A^Ty.
\label{normal-reg}
\end{equation}
Since $\Gamma > 0$ and $\Gamma^T\Gamma > 0$, the matrix $A^TA + \Gamma^T\Gamma$ is $> 0$ and thus
is invertible. Hence the analytic solution
$$
    x^*_{\Gamma} = (A^TA + \Gamma^T\Gamma)^{-1}A^Ty
$$
always exists.

Tikhonov regularization can also be seen as imposing a norm constraint, controlled by $\Gamma$, on
the solution in order to make the problem observable. This can be seen via arguments analogous
to those in the Lagrange multipliers section: If $x$ is a stationary point of
(\ref{glls-reg}), then we have
$$
    \nabla_x \| Ax - y \|_2^2 = -\nabla_x \| x \|_{\Gamma}^2,
$$
that is, the gradients of these two functions are (anti-)parallel. Hence, $x^*_{\Gamma}$ minimizes
$\|Ax - y\|_{\Gamma}^2$ subject to the constraint that $\| x \|_2 = \|x^*_{\Gamma}\|$, i.e.
$x^*_{\Gamma}$ is the optimal solution for its Mahalanobis norm under $\Gamma$. Hence, by
regularizing, we are solving the least-squares problem subject to a norm-constraint determined
by the matrix $\Gamma$. Note that $\|x^*_{\Gamma}\|$
and $\|\Gamma\|$ (for some choice of matrix norm) are inversely related; as
$\|\Gamma\| \to \infty$, $\|x^*_\Gamma\|_2 \to 0$.

\section{Fisher Information}

\section {Robust Estimation of Location}
\subsection{Location Parameters and $M$-Estimators}
If a family of probability distributions $\{ f_{\theta} : \theta \in \Theta\}$
has the form
$f_{\theta}(x) = f(x - \theta)$, then $\theta$ is called a \textbf{location parameter} of the family. Location parameters
determine the ``shift'' of a distribution; examples are the mean, median, and mode.

Formally, given a location family $\mathcal F = \{ f_{\theta} : \theta \in \Theta\}$, and a random variable
$X : \Omega \to \mathbb R$ whose distribution belongs to $\mathcal F$,
an \textbf{$M$-estimator} for the location parameter of $\mathcal X$ is (for each $n$) a function
$$
    t_n : \mathbb R^n \to \Theta
$$
taking the form
$$
    t_n(x_1, \ldots, x_n) = \argmin_{\theta \in \Theta} \sum_{i=1}^n \rho(x_i - \theta),
$$
where $\rho : \mathbb R \to \mathbb R$
is a convex function that tends to infinity as its argument approaches $\pm \infty$.
Two common examples of $M$-estimators are the sample mean
$t_n(x_1, \ldots, x_n) = \sum_i x_i /n$ and the sample median, which
are $M$-estimators for the functions $\rho(x) = x^2$ and $\rho(x) = |x|$, respectively.

Define $\psi = \rho'$, and assume that $\psi$ is continuous. Then $t_n$ is equivalently defined by
$$
    \sum_{i=1}^n \psi(x_i - t_n(x_1, \ldots, x_n)) = 0.
$$

\subsection{Asymptotic Normality}

Fix and underlying distribution $F$.
By viewing the arguments to $t_n$ as random variables with distribution $F$,
we can view $t_n$ as a $\Theta$-valued random variable.
We can thus consider its \textbf{asymptotic distribution}, i.e. the distribution of $t_n$ as $n \to \infty$.
Define $\lambda(\xi) = \mathbb E_x \psi(x - \xi)$. Assume that
\begin{enumerate}
    \item $\lambda(\theta^*) = 0$,
    \item $\lambda'(\theta^*) < 0$,
    \item $\int \psi^2(x - \theta^*) F(dx)$ is finite and continuous at $x = \theta^*$.
\end{enumerate}
Then $t_n$ is \textbf{asymptotically normal} with mean $\theta^*$ and \textbf{asymptotic variance}
$$
    V(\psi, F) = \frac{1}{\lambda'(\theta^*)^2} \int \psi^2(x - \theta^*) F(dx).
$$
That is, we have convergence in distribution:
$$
    t_n \xrightarrow{D} N(\theta^*, V(\psi, F)).
$$

Following are examples; we assume that all distributions are centered, i.e. $t_n \to 0$.

\subsubsection{Example: The Sample Mean}

Taking $\rho(x) = x^2$ gives $t_n = \sum_i x_i /n$, which is asymptotically normal with variance
\begin{align*}
    V & = \int x^2 F(dx).
\end{align*}
Observe that the sample mean is especially sensitive to the tails of $F$.

\subsubsection{Example: The Sample Median}

Taking $\rho(x) = |x|$ gives $t_n$ as the sample median of $\{x_i\}$, which is asymptotically normal with variance
\begin{align*}
    V & = \frac{1}{2F'(0)^2}.
\end{align*}
Note that the sample median is sensitive only to values near the distribution's median.

\subsubsection{Example: The Huber Loss Function}

Let
$$
\rho(x) =
\begin{cases}
    \frac{1}{2} x^2 & |x| \le k \\
    k|x| - \frac{1}{2} k^2 & |x| > k
\end{cases}
$$
be the \textbf{Huber loss function}, with \textbf{characteristic scale} $k$. Then $\rho(x)$ has the following properties:
\begin{enumerate}
    \item Any samples $x_i$ for which $|x_i - t_n| > k$ may be replaced by the closer of
    $t_n \pm k$ without changing the value
        of $t_n$.
    \item $t_n$ is the sample mean of the modified set of observations.
\end{enumerate}
Then $t_n$ is asymptotically normal with variance
\begin{align*}
    V & = \left(\int_{-k}^{+k} F(dx) - kF'(k) - kF'(-k)\right)^{-2} \int_{-k}^{+k} x^2F(dx).
\end{align*}

\subsection{Robust Estimation and Huber's Theorem}

We formalize the notion of ``robust'' estimation by considering a fixed distribution $G$, and a space
of ``contaminated'' distributions
$$
    \mathcal F = \{F = (1 - \epsilon) G + \epsilon H : H \in \mathcal D\},
$$
where $\epsilon \in [0, 1)$ is fixed, and
and $H$ is a varying distribution function. We then attempt to measure how the asymptotic
variance of $M$-estimators on $F \in \mathcal{F}$ are affected by $\epsilon$ and $H$. This setup models a
``true'' distribution $G$ contaminated such that a sample of size $n$ contains
some expected number $\epsilon n$ of outliers coming following
another distribution $H$. \textbf{Huber's theorem} addresses this by showing that $V(\psi, F)$ has a
\emph{saddle point}: we can find $F_0 = (1 - \epsilon) G + \epsilon H_0$ and $\psi_0$ such that
$$
    \sup_F V(\psi_0, F) = V(\psi_0, F_0) = \inf_{\psi} V(\psi, F_0),
$$
where we restrict to $\mathbb E_F \psi_0 = 0$. In other words, we can (under some technical conditions --- see
[Huber]XXX) minimize the supremum of the asymptotic variance of $t_n$ over all unbiased choices of $\psi$.

In fact, we have a formula for the minimizing $M$-estimator:
$$
    \psi_0 = -f'_0 / f_0,
$$
where $f_0$ is the density of $F_0$, and is given by
\begin{align*}
    f_0(x) &= (1 - \epsilon) g(x_0) e^{k(x - x_0)} & t \le x_0, \\
           &= (1 - \epsilon) g(x) & x_0 < x < x_1, \\
           &= (1 - \epsilon) g(x_1) e^{-k(x - x_0)} & x \ge x_1,
\end{align*}
where $[x_0, x_1]$ is the interval on which $|g'/g| \le k$, and $k \in \mathbb R$ is defined by
$$
    (1 - \epsilon)^{-1} = \frac{g(x_0) + g(x_1)}{k} + \int_{x_0}^{x_1} g(x) dx.
$$

\subsubsection{Special Case: The Contaminated Normal Distribution}

The special case of Huber's theorem where $G = \Phi$ is the standard normal distribution is of
particular significance. In this case, letting $k$ be defined by
$$
    (1 - \epsilon)^{-1} = \frac{2 \phi(k)}{k} + \int_{-k}^{+k} \phi(x) dx,
$$
the Huber loss function $\rho$ with characteristic scale $k$ minimizes
$\sup_F V(\psi, F)$ over all translation invariant estimators, where the $\sup$ is taken over all
symmetric $F = (1 - \epsilon) \Phi + \epsilon H$. In this case, the (least-favorable) $F_0$ has density
$$
    f_0(x) = (1 - \epsilon) \frac{1}{\sqrt{2 \pi}} e^{-\rho(t)},
$$
and the (worst-case) asymptotic variance is
$$
    \sup_F(\psi_0, F) = V(\psi_0, F_0) =
    \frac{(1 - \epsilon) \mathbb E_{\Phi} \psi^2 + \epsilon k^2}{\left( (1 - \epsilon) \mathbb E_{\Phi}\psi'\right)^2},
$$

\subsection{Asymptotic Relative Efficiency}

\section{Differential Geometry}
\subsection{Differentiable Manifolds}
\subsubsection{Motivation and Definition}
A \textbf{differentiable manifold} of dimension $n$ is a space $M$ which is locally approximated by $d$-dimensional
Euclidean space, in such a way that allows us to do calculus on $M$. In practice, this means that to each point
$p \in M$ we attach a \textbf{tangent space} $T_pM$, which is isomorphic (as a topological vector space) to
$\mathbb R^n$, in such a way that calculus done on the tangent spaces can be consistently ``transferred'' to
the manifold. Tangent vectors are viewed as infinitesimal ``directions'' on the manifold at a given point.
We do calculus on the tangent spaces, and the apply the results back to the manifold, analogous
to how we do 1-D calculus by applying ``infinitesimal'' perturbations to functions and observing the change in output.

Formally, we define a manifold to be a topological space $M$ satisfying some ``niceness'' conditions
(e.g. it is Haussdorf) together with a set of \textbf{charts} $(x, U)$, where $x : U \subseteq M \to \mathbb R^n$
is a homeomorphism, and for any two charts $(x, U)$ and $(y, V)$, the \emph{transition map}
$y \circ x^{-1}$ is differentiable. This compatibility condition allows us to define, for
instance, a function $f: M \to \mathbb R$ to be \textbf{differentiable} if $f \circ x^{-1}$ is differentiable for
any chart $(x, U)$.

\subsubsection{The Tangent and Cotangent Bundles}

Given a point $p \in M$, we can define \textbf{tangent space} $T_pM$
as the space of equivalence classes of curves $\gamma : I \ni 0 \to M$ with
$\gamma(0) = p$, with $[\gamma_1] = [\gamma_2]$ if $(x \circ \gamma_1)'(0) = (x \circ \gamma_2)'(0)$
for any chart $x$. We abuse notation and let $\gamma'(0)$ denote $(x \circ \gamma)'(0)$ for any chart $x$,
since this quantity is independent of choice of chart.

Note that this definition gives a natural identification with $\mathbb R^n$, via $[\gamma] \mapsto \gamma'(0)$.
This identification can be used to either define or justify (via isomorphism) addition and scalar multiplication
on $T_pM$ in the obvious way.

Observe that tangent vectors are naturally viewed as directional differentiation operators on $C^{\infty}(M)$: for
$v = \gamma'(0) \in T_pM$,
$$
    v(f) = (f \circ \gamma)'(0).
$$
The map $v \mapsto v(f)$ from $T_pM \to \mathbb R$ is linear, and is called the \textbf{differential} or
\textbf{pushforward} of $f$, denoted $df_p$. So we have
$$
    df_p(v) = v(f) = (f \circ \gamma)'(0).
$$
The differential can be viewed as the linearization of $f$ at $p$, using $f$ to ``push foward'' the tangent space.

The \textbf{tangent bundle} $TM$ of $M$ is the set $\{ (p, v) : v \in T_pM \}$, endowed with a canonical manifold
structure that is ``locally trivial'': around each point $p \in M$ there is a local neighborhood $U$
and a diffeomorphism $\phi : TU \to U \times \mathbb R^n$ that \emph{also} restricts to vector space isomorphism
between $T_p M \cong \mathbb R^n$ for each $p \in U$. In general it is not the case that $TM \cong M \times \mathbb R^n$
globally; the \textbf{hairy ball theorem} gives $TS^2 \not \cong S^2 \times \mathbb R^2$ as simple example of a
nontrivial tangent bundle.

The tangent bundle $T\mathbb R^n$, however, \emph{is} trivial, and this is why we can identify
$T_p\mathbb R^n \cong \mathbb R^n$ and thus greatly simplify calculus on Euclidean space.

The \textbf{cotangent bundle} $T^*M$ is the dual to the tangent bundle: we attach a copy of the
\textbf{cotangent space} $T^*_pM$ to each point of $M$ in the analogous fashion. In general, such a construct is
called a \textbf{vector bundle} on $M$. If the vector spaces attached to each point have additional structure,
we can require that that structure is preserved in the local trivializations.

\subsubsection{Sections, Tensor Bundles, and Exterior Bundles}

A \textbf{(differentiable) section} of a vector bundle $B$ over $M$ is a differentable mapping
$\sigma : M \to B$ such that $B(p)$ belongs the to vector space attached at $p$. A section of the tangent bundle
is a \textbf{vector field}. The $C^{\infty}(M)$-algebra of vector fields on $M$ is denoted $\Gamma(TM)$.
\textbf{covector fields} (also called \textbf{one-forms}) are defined similarly.

We may view a vector field $V$ as a differentiation operator on smooth functions: $V : C^{\infty}(M) \to C^{\infty}(M)$
via
$$
    (Vf)(p) = V_p(f) = df_p(V_p).
$$
Dually, we may view the differential as a one-form, acting on vector fields: $df : \Gamma(TM) \to C^{\infty}(M)$ via
$$
    df(V) = Vf.
$$

We may apply an operation that we apply to a vector space to a vector bundle $B$ on $M$ by
applying the operation ``fiber-wise``. In particular, we can define the \textbf{type-(r,s) tensor bundle} on $M$ by
$$
    \mathcal T^r_s(M) = TM^{\otimes r} \otimes T^*M^{\otimes s}.
$$
A \textbf{tensor field} is then a section of a tensor bundle on $M$. Tensor fields are ubiquitous construction on
manifolds; they subsume both vector fields and covector fields. See the sections on Riemannian metrics and
the Riemann curvature tensor below.

Another canonical example of a vector bundle on $M$ is the \textbf{$k$-th order exterior bundle}
$\bigwedge^k(T^*M)$. A section of this bundle is a \textbf{differential $k$-form} on $M$. Integration of forms on
manifolds is currently beyond the scope of these notes, but they allow for the statement of the famous
Stokes' Theorem, $\int_{\partial M} \omega = \int_M d\omega$.

\subsubsection{Pushforwards}

More generally, we can define the differential (also known as the \textbf{pushforward}) of a mapping
$\varphi : M \to N$ between manfolds. The pushforward generalizes the full derivative in Euclidean space.
The pushforward, denoted, $d\varphi$ or $\varphi_*$, is a mapping between
tangent bundles:
\begin{align*}
    \varphi_* &: TM \to TN \\
    \varphi_* &: V \mapsto (g \mapsto V(g \circ \varphi))
\end{align*}
for $g \in C^{\infty}(N)$. The restriction of $\varphi_*$ to a tangent space is a linear map:
\begin{align*}
    (\varphi_*)_p &: T_pM \to T_{\varphi(p)}N \\
    (\varphi_*)_p &: V_p \mapsto (g \mapsto V_p (g \circ \varphi)).
\end{align*}

The pushforward allows us to define various ``morphisms'' between manifolds: we say that $\varphi: M \to N$ is a
\begin{itemize}
    \item \textbf{submersion} if $\operatorname{rank}(\varphi_*)_p = \dim N$ for every $p \in M$
    (i.e. the pushforward is surjective on each tangent space),
    \item \textbf{immersion} if $\operatorname{rank}(\varphi_*)_p = \dim M$ for every $p \in M$
    (i.e. the pushforward is injective on each tangent space),
    \item \textbf{embedding} if $\varphi$ is an injective immersion.
\end{itemize}
The \textbf{Whitney embedding theorem} is a deep theorem in differential geometry, which
states that every manifold $M$ can be embedded in $\mathbb R^{2 \dim M}$. Note that this is not obvious;
we can for instance easily see that $S^2$ can be embedded in $\mathbb R^3$, but it is not obvious that its
tangent bundle $TS^2$ can be embedded into any Euclidean space.

\subsubsection{Local Coordinates}

Let $(x, U)$ be a chart on $M$. We can view $x$ as giving a system of local coordinates on the manifold, via
$x(p) = (x_1(p), \ldots, x_n(p))^T \in \mathbb R^n$.
These coordinates induce
coordinates on the (local) tangent and cotangent bundles, $TU$ and $T^*U$. Particularly, if we let
$x^i \in C^{\infty}(M)$ be the $i$-th coordinate of $x$, then the one-forms $dx^i \in \Gamma(T^*U)$ form a basis for
$\Gamma(T^*U)$. We let the dual basis be called $\frac{\partial}{\partial x_i} \in \Gamma(TU)$. Then the vector
field $\frac{\partial}{\partial x_i}$ acts on $f \in C^{\infty}(U)$ by
$$
    \frac{\partial}{\partial x_i} f = (f \circ (t \mapsto x^{-1}(x  + t e_i)))'(0),
$$
which, for a given point $p \in U$, is the usual partial derivative of $f \circ x^{-1}$. We denote this quantity by
$\frac{\partial f}{\partial x_i}$, in an abuse of notation. Hence any vector field $V \in \Gamma(TU)$ can be written
as
$$
    V = V^i \frac{\partial}{\partial x_i},
$$
acting on functions by
$$
    Vf = V^i \frac{\partial f}{\partial x_i}.
$$
Here we use \textbf{Einstein notation}, where the sum over $i$ is implicit.

Similarly, any one-form $df$ can be written as
$$
    df = \frac{\partial f}{\partial x_i} dx^i.
$$

The pushforward of a map $\varphi : M \to N$ is given in local coordinates by the Jacobian matrix:
$$
    (\varphi_*)_i^j = \frac{\partial \varphi_j}{\partial x_i}.
$$
where $x$ and $y$ are coordinates on $M$ and $N$, respectively.
Note that, here, $\varphi_j$ is shorthand for $(y \circ \varphi)_j : V \subseteq N \to \mathbb R^m$.

\subsubsection{Integral Curves and Flow}

Given a vector field $V \in \Gamma(TM)$ and a point $p \in M$, an \textbf{integral curve} for $V$ passing through $p$
is a curve $\gamma : J \subseteq I \to M$ such that
\begin{align*}
    \gamma(t_0) &= p \\
    \gamma'(t) &= V_{\gamma(t)}
\end{align*}
for all $t \in J$. Under a choice of local coordinates $x$, this condition becomes the IVP
\begin{align*}
    \gamma(t_0) &= p \\
    \frac{d \gamma_i}{dt} &= V^i,
\end{align*}
so a (local) solution always exists and is unique,
using the Picard-Lindelof theorem.

More generally, we can consider the \textbf{flow} of the vector field $V$, i.e. the mapping
$\Phi : D \subseteq \mathbb R \times M \to M$ satisfying
\begin{align*}
    \Phi^0(p) &= p \\
    \frac{d}{dt} \Phi^t(p) &= V_{\Phi^t(p)},
\end{align*}
defined (uniquely) on some maximal domain $D$. The map $t \mapsto \Phi^t$ is a
\textbf{one-parameter subgroup} of local diffeomorphisms on $M$---for each $t$, $p \mapsto \Phi^t(p)$
is a local diffeomorphism from $U \to \Phi^t(U)$, and the map obeys the group law:
$$
    \Phi^s \circ \Phi^t = \Phi^{s+t}.
$$

\subsubsection{The Lie Derivative}

The \textbf{Lie derivative} evaulates the change in a vector (scalar, tensor) field along the flow defined
by a vector field. For scalar fields $f \in C^{\infty}(M)$, the definition of the Lie derivative $\mathcal L_Vf \in
C^{\infty}(M)$ is
$$
\mathcal L_X f(p) = \lim_{t \to 0} \frac{f(\Phi^t(p)) - f(p)}{t}.
$$

For vector fields, we would like to define the analogous
$\mathcal (L_X W)_p = \lim_{t \to 0} \frac{1}{t}(d\Phi^t_p W_p - W_p)$. But as we have no way of comparing vectors
in different tangent spaces in a coordinate-independent manner, this notion isn't well-defined. Instead, we must
map all values of $Y$ ``back'' into $T_pM$ via $\Phi^t$. Hence we define
$$
    \mathcal (L_V W)_p = \lim_{t \to 0} \frac{d\Phi^{-t}_{\Phi^t(p)}W_{\Phi^t(p)} - W_p}{t}.
$$

In coordinates, this yields
$$
    (\mathcal L_V W)^i = V^j \frac{\partial W_i}{\partial x_j} - W^j \frac{\partial V_i}{\partial x_j}.
$$

Defining the \textbf{Lie bracket} of two vector fields via
$$
    [V,W]f = VWf - WVf,
$$
we have
$$
    \mathcal L_V W = [V, W].
$$

It is important to note that the Lie derivative depends (anti)-symmetrically on local values of both $V$ and $W$;
so we cannot e.g. take the Lie derivative of a single vector, or take the Lie derivative along a curve.

\subsection{Riemannian Geometry}
\subsubsection{Riemannian Metrics}

A \textbf{Riemannian metric} on a manifold $M$ is a smooth section of the bundle of
symmetric positive-definite bilinear forms on $TM$. That is, $g \in \Gamma(T^*M \otimes T^*M$) is symmetric and 
positive-definite. A Riemannian metric induces an inner product $g_p$ on each tangent space $T_pM$, thus endowing
each tangent space with a notion of length and angle. In local coordinates, we can write
$$
    g = g_{ij} dx^i \otimes dx^j.
$$

Furthermore, a Riemannian manifold $(M, g)$ is also a \emph{length metric space}: If $\gamma : [a,b] \to M$ is
a curve, then we can define its \emph{arc length}:
$$
    L(\gamma) = \int_a^b \sqrt{g(\gamma'(t), \gamma'(t))} dt.
$$
The distance between two points is then
$$
    d(p,q) = \inf\{L(\gamma) \mid \gamma(a) = p, \; \; \gamma(b) = q\}.
$$

\subsubsection{Covariant Derivatives}

The existence of a Riemannian metric also allows us to canonically identify different tangent spaces, through
the machinery of a \textbf{covariant derivative}, also called an
\textbf{affine connection}. Intuitively, the structure of an affine connection means that
$M$ looks locally like $\mathbb R^n$ not only as a vector space, but as an \emph{affine space}. This allows
us to develop notions of parallel transport of vectors, and to differentiate vector fields as if they were functions
on the manifold, taking values in the same vector space.

Formally, a covariant derivative is an differentiation operator on vector fields that differentiate one
vector field along another. 
As motivation, we consider a manifold $M$
isometrically embedded in $\mathbb R^m$ via a smooth mapping $\Phi : M \to \mathbb R^m$.
In this case, the vectors $\frac{\partial \Phi}{\partial x_i}$ form a basis for $T_pM$ at each $p$, and
the metric agrees with the ambient metric in $\mathbb R^m$ :
$g_{ij} = \left\langle \frac{\partial \Phi}{\partial x_i}, \frac{\partial \Phi}{\partial x_j} \right\rangle$.

In this situation, we may differentiate a vector field $V = V^i \frac{\partial \Phi}{\partial x_i}$ along
(for simplicity) a unit vector (field) $\frac{\partial}{\partial x_i} \in \Gamma(TM)$ as follows: First, take
the derivative in the ambient Euclidean space:
$$
    \frac{\partial V}{\partial x_i}
        = \frac{\partial V_j}{\partial x_i}\frac{\partial \Phi}{\partial x_j} +
            V^j \frac{\partial^2 \Phi}{\partial x_i \partial x_j},
$$
and then we project the second component of this vector back into the tangent space; for some section $n$
of the ``normal bundle'' $NM$, we can decompose the second derivate along the direct sum
$T\mathbb R^m = TM \oplus NM$:
$$
    \frac{\partial^2 \Phi}{\partial x_i \partial x_j}
        = \Gamma^k_{ij} \frac{\partial \Phi}{\partial x_k} + n.
$$
We then project by simply dropping $n$, and define the \textbf{covariant derivative} along a coordinate tangent
vector by
$$
    \nabla_{\frac{\partial}{\partial x_i}} V = \left( \frac{\partial V^k}{\partial x_i} + V^j \Gamma^k_{ij}
        \right) \frac{\partial \Phi}{\partial x_k}.
$$
This (canonical) choice of connection (extended linearly to all of $\Gamma(TM)$)
is called the \textbf{Levi-Civita connection}.
The coefficients $\Gamma^k_{ij}$ are called the \textbf{Christoffel symbols} of the connection, and they satisfy
the following relation with the metric:
\begin{equation}
    g_{kl}  = \Gamma^k_{ij} \frac 12 \left(\frac{\partial g_{jl}}{\partial x_i}
        + \frac{\partial g_{li}}{\partial x_j} + \frac{\partial g_{ij}}{\partial x_l} \right).
\label{christoffel}
\end{equation}

It turns out that the Levi-Civita connection on $M$ in this embedded setting
is uniquely specified by the following set of properties: it is the unique bilinear map
$\nabla : \Gamma(TM) \times \Gamma(TM) \to \Gamma(TM)$ satisfying
\begin{enumerate}
    \item $\nabla_{f W} V = f \nabla_W V$ (i.e. linearity in the vector field that we are differentiating along).
    \item $\nabla_W (fV) = df(V)W + f \nabla_W V$ (i.e. satifies a product rule in the vector field being differentiated).
    \item $\nabla$ preserves the metric: $\nabla g = 0$.
    \item $\nabla$ is \emph{torsion-free}, i.e. $\nabla_W V - \nabla_V W = [V, W]$.
\end{enumerate}
Note that (1) and (2) are metric-independent; any bilinear map satisfying these is a general affine connection;
imposing (3) and (4) gives the unique Levi-Civita connection. We generalize to non-embedded manifolds by simply
taking these as the definition of the connection. The existence and uniqueness of the
Levi-Civita connection is known as the \textbf{fundamental theorem of Riemannian
geometry}.

\subsubsection{Differentiating along Curves, Parallel Transport, and Geodesics}

It is crucial to notice that an affine connection gives us a definition of $\nabla_v V$ for $v \in T_pM$; that is,
$(\nabla_V W)_p$ depends on local values of $V$, but only on the value of $W$ at $p$. Hence the connection gives
us the ability to differentiate along curves: given a curve $\gamma : I \to M$, we define
$$
    \frac{DV}{dt} = \nabla_{\gamma'(t)} V.
$$

A vector field $V$ along a curve $\gamma$ is called \textbf{parallel} if $\nabla_{\gamma'} V = 0$.
The \textbf{parallel transport} of a vector $v \in T_pM$ along $\gamma$ is the unique extension of $v$
to a parallel vector field along $\gamma$.

A \textbf{geodesic} is a curve $\gamma$ for which $\nabla_{\gamma'} \gamma' = 0$. Geodesics are the locally-shortest
paths; if $d(p,q) = \int_a^b \sqrt{g(\gamma'(t), \gamma'(t))} dt$, then, $\gamma$ is a geodesic.

\subsubsection{The Exponential Map and Normal Coordinates}

\section{Lie Groups}

\begin{thebibliography}{999}

\bibitem{nocedal}
Nocedal \& Wright,
\emph{Numerical Optimization}.
Springer Series In Optimization Research,
Second Edition,
2006.

\bibitem{huber}
Huber, Peter J.,
\emph{Robust Estimation of a Location Parameter}.
University of California, Berkeley,
1963.

\end{thebibliography}

\end{document}
